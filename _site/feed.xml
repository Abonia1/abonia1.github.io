<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en" /><updated>2024-04-10T13:33:59+02:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Abonia Sojasingarayar</title><subtitle>Holds a Masters degree in Artificial Intelligence and boasts over 7 years of experience. With a robust background in crafting and implementing ML systems across diverse domains, including cybersecurity, banking, transit,cosmetics &amp; hygiene research, and e-commerce.
</subtitle><author><name>Abonia Sojasingarayar</name><email>aboniaa@gmail.com</email></author><entry><title type="html">How I Passed the GCP Professional Data Engineer Exam</title><link href="http://localhost:4000/blogs/2024-04-09-How-I-Passed-the-GCP-Professional/" rel="alternate" type="text/html" title="How I Passed the GCP Professional Data Engineer Exam" /><published>2024-04-09T00:00:00+02:00</published><updated>2024-04-09T19:27:02+02:00</updated><id>http://localhost:4000/blogs/How-I-Passed-the-GCP-Professional</id><content type="html" xml:base="http://localhost:4000/blogs/2024-04-09-How-I-Passed-the-GCP-Professional/"><![CDATA[<p><strong>Date:</strong> 2024-04-09<br />
  <strong>Reading_time:</strong> 6 min<br />
  <strong>Tags:</strong> [GCP, Data Engineering, Cloud, Certification]</p>
<ul class="large-only" id="markdown-toc">
  <li><a href="#1-basic-concept-from-udemy-courses" id="markdown-toc-1-basic-concept-from-udemy-courses">1. Basic concept from udemy courses</a></li>
  <li><a href="#2google-official-video-coursestheory--practical" id="markdown-toc-2google-official-video-coursestheory--practical">2.Google official video courses(Theory + Practical)</a></li>
  <li><a href="#3-books-and-resource" id="markdown-toc-3-books-and-resource">3. Books and resource</a></li>
  <li><a href="#4-official-documentation" id="markdown-toc-4-official-documentation">4. Official documentation</a></li>
  <li><a href="#5-quizzesexamtopicsmock-test" id="markdown-toc-5-quizzesexamtopicsmock-test">5. Quizzes/ExamTopics/Mock test</a></li>
  <li><a href="#6-cheatsheet" id="markdown-toc-6-cheatsheet">6. <strong><em>Cheatsheet</em></strong></a></li>
  <li><a href="#7-notes" id="markdown-toc-7-notes">7. Notes</a></li>
  <li><a href="#8-tips" id="markdown-toc-8-tips">8. Tips</a></li>
  <li><a href="#9-assessment" id="markdown-toc-9-assessment">9. Assessment</a></li>
  <li><a href="#colclusion" id="markdown-toc-colclusion">Colclusion:</a></li>
  <li><a href="#success-is-easy-to-achieve-once-you-set-your-mind-on-a-specific-goal" id="markdown-toc-success-is-easy-to-achieve-once-you-set-your-mind-on-a-specific-goal">Success is easy to achieve once you set your mind on a specific goal.</a></li>
  <li><a href="#--atticus-aristotle" id="markdown-toc---atticus-aristotle">- Atticus Aristotle</a></li>
</ul>
<p><strong>Table of Contents:</strong></p>
<ul>
  <li><a href="#1-basic-concept-from-udemy-courses">Basic concept from udemy courses</a></li>
  <li><a href="#2google-official-video-coursestheory--practical">Google official video courses(Theory + Practical)</a></li>
</ul>

<p><strong>In this article , I would like to share my experiences for preparing and taking the exam. I hope theyâ€™ll help you in one way or another.</strong></p>

<p>Google Cloud Certified Professional Data Engineer exam tests your ability to design, deploy, monitor, and adapt services and infrastructure for data-driven decision-making.</p>

<p>The whole preparation took me nearly 2 months , but with some more focus time I couldâ€™ve done it in 1 month. Following steps that I have taken to pass the exam :</p>

<ul>
  <li>
    <p>Basic concept from udemy course</p>
  </li>
  <li>
    <p>Google official video courses(Theory + Practical)</p>
  </li>
  <li>
    <p>Books and resources</p>
  </li>
  <li>
    <p>Official documentation</p>
  </li>
  <li>
    <p>Quizzes/ExamTopics/Mock test</p>
  </li>
  <li>
    <p>Cheatsheet</p>
  </li>
  <li>
    <p>Notes</p>
  </li>
  <li>
    <p>Assessment</p>
  </li>
  <li>
    <p>Tips</p>
  </li>
</ul>

<h3 id="1-basic-concept-from-udemy-courses">1. Basic concept from udemy courses</h3>

<p>I have followed the course <strong><em><a href="https://www.udemy.com/course/google-cloud-professional-data-engineer-get-certified/">Google Cloud Professional Data Engineer: Get Certified 2022</a></em></strong> by Dan Sullivan. I have followed all the classes in this course.As for public it costs 79,99â‚¬ and it covers following topics:</p>

<ul>
  <li>
    <p>Build scalable, reliable data pipelines</p>
  </li>
  <li>
    <p>Choose appropriate storage systems, including relational, NoSQL and analytical databases</p>
  </li>
  <li>
    <p>Apply multiple types of machine learning techniques to different use cases</p>
  </li>
  <li>
    <p>Deploy machine learning models in production</p>
  </li>
  <li>
    <p>Monitor data pipelines and machine learning models</p>
  </li>
  <li>
    <p>Design scalable, resilient distributed data intensive applications</p>
  </li>
  <li>
    <p>Migrate data warehouse from on-premises to Google Cloud</p>
  </li>
  <li>
    <p>Evaluate and improve the quality of machine learning models</p>
  </li>
  <li>
    <p>Grasp fundamental concepts in machine learning, such as backpropagation, feature engineering, overfitting and underfitting.</p>
  </li>
</ul>

<p>At the end of the course there will be 50 sample questions to solve which gives you 2 hours as like you are in exam.</p>

<h3 id="2google-official-video-coursestheory--practical">2.Google official video courses(Theory + Practical)</h3>

<p>I recommend to go through all the <strong><em><a href="http://Professional Data Engineer">Professional Data Engineer Google course</a></em></strong> videos and practicals from the official site.</p>

<p>Official guide for the data engineer exam is <a href="https://cloud.google.com/certification/guides/data-engineer">here</a>.</p>

<p>This course covers following topics:</p>

<ul>
  <li>
    <p>Design data processing systems</p>
  </li>
  <li>
    <p>Ensure solution quality</p>
  </li>
  <li>
    <p>Operationalize machine learning models</p>
  </li>
  <li>
    <p>Build and operationalize data processing systems</p>
  </li>
</ul>

<p>It has following 9 major classes with which you can attain a badge from google :</p>
<blockquote>
  <ol>
    <li>Google Cloud Big Data and Machine Learning Fundamentals</li>
    <li>Data Engineering on Google Cloud</li>
    <li>Serverless Data Processing with Dataflow Specialization</li>
    <li>Create and Manage Cloud Resources</li>
    <li>Perform Foundational Data, ML, and AI Tasks in Google Cloud</li>
    <li>Engineer Data in Google Cloud</li>
    <li>Preparing for the Google Cloud Professional Data Engineer Exam</li>
    <li>Professional Data Engineer</li>
    <li>Register for your certification exam</li>
  </ol>
</blockquote>

<p>I have followed the above courses using Partner account so it was completely free and there were free credits available to solve the lab.</p>

<ul>
  <li>
    <p><strong><em><a href="https://linuxacademy.com/course/google-cloud-data-engineer/">Linux Academy course</a></em></strong> (Took 4 weeks + 2 weeks (revision)) â€” 75% success rate</p>
  </li>
  <li>
    <p><strong><em><a href="https://www.coursera.org/professional-certificates/gcp-data-engineering">Coursera GCP Data Engineering Specialization</a></em></strong> (6 courses)(Took ~4 Weeks) â€” 20%</p>
  </li>
</ul>

<h3 id="3-books-and-resource">3. Books and resource</h3>

<p>I strongly recommend you to going through <strong><em><a href="https://www.oreilly.com/library/view/official-google-cloud/9781119618430/f07.xhtml#usec0005">Official Google Cloud Certified Professional Data Engineer Study Guide</a></em></strong> [Book] by Dan Sullivan. This study guide offers 100% coverage of every objective for the Google Cloud Certified Professional Data Engineer exam.</p>

<p>This books covers most of the exam topics and there are around 20 quizzes for each chapter.</p>

<h3 id="4-official-documentation">4. Official documentation</h3>

<p>It is also very important to going through the <strong><em><a href="https://cloud.google.com/">official documentation</a></em></strong> to get updated information about the google products and services.</p>

<p><em>For example,sometimes an old mock questionâ€™s answers will guide you in a wrong way. Access control on table level is now possible in BigQuery but it wasnâ€™t before.</em> So please dont follow the quiz answers that were provided by default but also I recommend you to do your proper search in official docs , if you have doubt in it.I have used this scenerio as an example and there are other similar cases.</p>

<h3 id="5-quizzesexamtopicsmock-test">5. Quizzes/ExamTopics/Mock test</h3>

<p>Most important part of the preparation is going through as many quizzes as possible and verifing with reasonable answer. To pass the actual exam, you have to spend more time on learning &amp; re-learning through multiple practice tests.</p>

<p>I recommend the following sites for preparing exam:</p>

<ol>
  <li>
    <p><strong><em><a href="https://www.examtopics.com/exams/google/professional-data-engineer/">Examtopics</a></em></strong> : There will be robotic check once after 10 questions and we should pay to get rid of those check and which allow you to focus well in the preparation.Please be aware of wrong answers in Examtopics try to do a search by yourself to assure that its the correct one. Cost : <strong>FREE</strong></p>
  </li>
  <li>
    <p><strong><em><a href="https://www.passnexam.com/google/google-data-engineer/01">PassExam</a></em></strong>: I have also prepared with PassExam which provides right answers for most of the questions with a reason in description and related offical links. Cost : <strong>FREE</strong></p>
  </li>
  <li>
    <p><strong><em><a href="https://www.whizlabs.com/blog/google-cloud-professional-data-engineer-exam-questions/">WhizLabs</a></em></strong> : There are around 25 multiple choice questions with what we can able to get insights on the certification and feel a little more confident. Cost : <strong>FREE</strong></p>
  </li>
  <li>
    <p><strong><em><a href="https://docs.google.com/forms/d/e/1FAIpQLSfkWEzBCP0wQ09ZuFm7G2_4qtkYbfmk_0getojdnPdCYmq37Q/viewform">Sample Questions fom Google</a></em></strong> : There are around 25 sample questions from google at the end of its official course.You can get the answer and explanation once you submit the form. But it is not guaranteed to help you pass the exam.</p>
  </li>
</ol>

<h3 id="6-cheatsheet">6. <strong><em>Cheatsheet</em></strong></h3>

<p>I recommend you to go through the <strong><em><a href="https://github.com/ml874/Data-Engineering-on-GCP-Cheatsheet/blob/master/data_engineering_on_GCP.pdf">Cheatsheet</a></em></strong> once. Cheatsheet is currently a 9-page reference Data Engineering on the Google Cloud Platform. It covers the data engineering lifecycle, machine learning, Google case studies, and GCPâ€™s storage, compute, and big data products.</p>

<p>Going through only this cheatsheet is not guaranteed to help you pass.But it can help you with your revision and refreshing the topics that you have pepared over the period before.</p>

<h3 id="7-notes">7. Notes</h3>

<p>Note taking app : [<strong>Notion](https://www.notion.so)</strong>. The best app for note taking.</p>

<p>Notion has helped us to <strong>revise effectively before exams on all the essential topics.</strong>I recommend to take notes for following topics.</p>

<p>These are the core GCP products that the assessment covers.</p>

<ul>
  <li>
    <p><a href="https://cloud.google.com/ai-platform/docs/technical-overview">AI Platform</a> (+ general AI and ML concepts)</p>
  </li>
  <li>
    <p><a href="https://cloud.google.com/bigquery">BigQuery</a></p>
  </li>
  <li>
    <p><a href="https://cloud.google.com/bigtable">BigTable</a></p>
  </li>
  <li>
    <p><a href="https://cloud.google.com/sql">Cloud SQL</a></p>
  </li>
  <li>
    <p><a href="https://cloud.google.com/dataflow">Dataflow</a></p>
  </li>
  <li>
    <p><a href="https://cloud.google.com/dataproc">Dataproc</a></p>
  </li>
  <li>
    <p><a href="https://cloud.google.com/pubsub">Pub/Sub</a></p>
  </li>
</ul>

<p>But there was some overlap with other Google tools too.</p>

<ul>
  <li>
    <p><a href="https://cloud.google.com/storage">Cloud Storage</a></p>
  </li>
  <li>
    <p><a href="https://cloud.google.com/spanner">Cloud Spanner</a></p>
  </li>
  <li>
    <p><a href="https://cloud.google.com/composer">Composer</a></p>
  </li>
  <li>
    <p><a href="https://cloud.google.com/compute">Compute Engine</a></p>
  </li>
  <li>
    <p><a href="https://cloud.google.com/dlp">Data Loss Prevention</a></p>
  </li>
  <li>
    <p><a href="https://cloud.google.com/dataprep">Dataprep</a></p>
  </li>
  <li>
    <p><a href="https://cloud.google.com/datastore">Datastore</a></p>
  </li>
  <li>
    <p><a href="https://firebase.google.com/docs/firestore">Firestore</a></p>
  </li>
  <li>
    <p><a href="https://cloud.google.com/natural-language">Natural Language AI</a></p>
  </li>
  <li>
    <p><a href="https://www.tensorflow.org/">Tensorflow</a></p>
  </li>
  <li>
    <p><a href="https://cloud.google.com/text-to-speech">Text-to-speech</a></p>
  </li>
  <li>
    <p><a href="https://cloud.google.com/video-intelligence">Video AI</a></p>
  </li>
</ul>

<h3 id="8-tips">8. Tips</h3>

<ul>
  <li>
    <p>Preparation is key to success. so many weekends, many holidays, I spent preparing for this exam.</p>
  </li>
  <li>
    <p>You can eliminate all the answer that recommend <strong>non-GCP solutions</strong>.</p>
  </li>
  <li>
    <p>As with many multiple-choice exams, <strong>eliminate</strong>. If you canâ€™t eliminate to one possible answer, make a guess.</p>
  </li>
</ul>

<h3 id="9-assessment">9. Assessment</h3>

<p>I took the assessment via Kryterionâ€™s <a href="https://www.webassessor.com/googlecloud/">Webassessor</a>. <strong>Exam Duration</strong>: 2 hours, <strong>Registration fee</strong>: $200 (plus tax where applicable) <strong>, Languages</strong>: English, Japanese and <strong>Exam format</strong>: Multiple choice and multiple select taken remotely or in person at a test center.</p>

<p>On exam day, I had to show my surroundings via webcam, turn off my phone, empty my desk, If your name is not visible you should take photo from your mobile a,d then you should show it to the sponser staff at the other end etc. All this took ~ half an hour. I didnâ€™t have to talk to the person behind the camera, but we can chat. The person also monitor you via webcam during the assessment.</p>

<p>I found the questions are bit hard and challenging. In the end, I got a provisional <em>Pass</em>, but it should be confirmed by Google â€” for whatever reason. That confirmation came 4 â€“10 days later. So now I am officially Google Certified Professional Data Engineer ðŸŽ‰ and here is my Official Google Certification!</p>

<p><img src="https://cdn-images-1.medium.com/max/2548/1*73NRxlyIZ8OH_2-CSYK4dQ.png" alt="Image by Author on [Professional Data Engineer Certification](https://www.credential.net/4e184ed8-23eb-4783-810c-a3c3e4e10b7d)" /></p>

<p>Tada ðŸŽ‰</p>

<p><img src="https://cdn-images-1.medium.com/max/2214/1*-kDC5Id6bejn-wY7aRlHAw.jpeg" alt="Image by Author" /></p>

<p>Got this amazing <strong>Google hoodie</strong> for free from google, after a month from the date of ordering. You can order it via the link that they send you with your official confirmation mail.</p>

<h2 id="colclusion">Colclusion:</h2>

<p>I hope this will help you pass the exam. All in all, you need to have solid Google Cloud knowledge to start with. If you are not familiar with the technology, the advised courses will help you. To get well prepared for the exam, I encourage you to complete the Official Data Engineer course videos and read about the best practices of GCP products, followed by the ML Crash Course provided by Google or Coursera. You should be ready to pass the exam by combining your studies with your knowledge. Good luck!</p>
<blockquote>
  <h1 id="success-is-easy-to-achieve-once-you-set-your-mind-on-a-specific-goal">Success is easy to achieve once you set your mind on a specific goal.</h1>
  <h1 id="--atticus-aristotle">- Atticus Aristotle</h1>
</blockquote>

<p><strong>Wish you the very best with your GCP certifications. You can reach me via:</strong></p>

<blockquote>
  <p><strong>Connect with me on <a href="https://www.linkedin.com/in/aboniasojasingarayar/">Linkedin</a></strong></p>
</blockquote>

<blockquote>
  <p><strong>Find me on <a href="https://github.com/Abonia1">Github</a></strong></p>
</blockquote>

<blockquote>
  <p><strong>Visit my technical channel on <a href="https://www.youtube.com/@AboniaSojasingarayar">Youtube</a></strong></p>
</blockquote>

<blockquote>
  <p><strong>Support: <a href="https://www.buymeacoffee.com/abonia">Buy me a Cofee/Chai</a></strong></p>
</blockquote>]]></content><author><name>Abonia Sojasingarayar</name><email>aboniaa@gmail.com</email></author><category term="blogs" /><summary type="html"><![CDATA[Learn about my journey of preparing for and passing the Google Cloud Certified Professional Data Engineer exam.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/img/blog/gcp-exam.webp" /><media:content medium="image" url="http://localhost:4000/assets/img/blog/gcp-exam.webp" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Deploying a RAG Application in AWS Lambda using Docker and ECR</title><link href="http://localhost:4000/blogs/2024-03-05-Deploying-a-RAG-Application-in-AWS-Lambda-using-Docker-and-ECR/" rel="alternate" type="text/html" title="Deploying a RAG Application in AWS Lambda using Docker and ECR" /><published>2024-03-05T00:00:00+01:00</published><updated>2024-04-10T13:33:58+02:00</updated><id>http://localhost:4000/blogs/Deploying-a-RAG-Application-in-AWS-Lambda-using-Docker-and-ECR</id><content type="html" xml:base="http://localhost:4000/blogs/2024-03-05-Deploying-a-RAG-Application-in-AWS-Lambda-using-Docker-and-ECR/"><![CDATA[<p><strong>Date:</strong> 2024-03-05<br />
  <strong>Reading_time:</strong> 6 min<br />
  <strong>Tags:</strong> [AWS, Lambda , ECR ,Docker , LangChain, OpenAI]</p>
<ul class="large-only" id="markdown-toc">
  <li><a href="#lambda--ecr--docker--langchain--openai" id="markdown-toc-lambda--ecr--docker--langchain--openai">Lambda â€” ECR â€” Docker â€” LangChain â€” OpenAI</a></li>
  <li><a href="#services-overview" id="markdown-toc-services-overview">Services Overview</a></li>
  <li><a href="#integration-and-deployment-steps" id="markdown-toc-integration-and-deployment-steps">Integration and Deployment Steps</a></li>
  <li><a href="#implementation" id="markdown-toc-implementation">Implementation</a>    <ul>
      <li><a href="#environment-setup" id="markdown-toc-environment-setup">Environment Setup</a></li>
      <li><a href="#data-loading-and-processing" id="markdown-toc-data-loading-and-processing">Data Loading and Processing</a></li>
      <li><a href="#response-generation" id="markdown-toc-response-generation">Response Generation</a></li>
      <li><a href="#aws-lambda-handler" id="markdown-toc-aws-lambda-handler">AWS Lambda Handler</a></li>
    </ul>
  </li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
  <li><a href="#thanks-for-reading" id="markdown-toc-thanks-for-reading"><em>Thanks for Reading!</em></a></li>
</ul>

<h3 id="lambda--ecr--docker--langchain--openai">Lambda â€” ECR â€” Docker â€” LangChain â€” OpenAI</h3>

<p>Deploying a RAG (Retrieval-Augmented Generation) application in AWS Lambda using Docker and Amazon Elastic Container Registry (ECR) with LangChain involves several steps and services. This article will explain each service and how they work together in an integrated way, followed by the steps to deploy it.</p>

<p>Here is the link to the complete tutorial on <strong><a href="https://youtu.be/gicsb9p7uj4?si=9F2l6z1rNpkUOoIR">Deploying RAG in AWS</a></strong>.</p>

<p>Before proceeding further, I would like to kindly suggest that you take some time to read and watch the tutorial titled <strong><a href="https://medium.com/@abonia/build-and-deploy-llm-application-in-aws-cca46c662749">Build and Deploy LLM Application in AWS</a></strong>. This tutorial can provide you with a solid foundation on Lambda LLM application deployment.
<strong><a href="https://medium.com/@abonia/build-and-deploy-llm-application-in-aws-cca46c662749">Build and Deploy LLM Application in AWS</a></strong></p>

<h2 id="services-overview">Services Overview</h2>

<p><img src="https://cdn-images-1.medium.com/max/3840/1*KBp2fuAVMvBfpE10p4nrrQ.png" alt="Architecture Overview â€” Image by Author" /></p>

<p><a href="https://aws.amazon.com/lambda/getting-started/?gclid=CjwKCAjwzN-vBhAkEiwAYiO7oF7Q4aEK3hKUA0HVPEe3wXKen_tVUDmxun4s5PjasxZ-deFf-j19vxoCovkQAvD_BwE&amp;trk=65546593-a75a-4317-b5dc-80218abfdb10&amp;sc_channel=ps&amp;s_kwcid=AL!4422!3!651542249938!e!!g!!aws%20lambda&amp;ef_id=CjwKCAjwzN-vBhAkEiwAYiO7oF7Q4aEK3hKUA0HVPEe3wXKen_tVUDmxun4s5PjasxZ-deFf-j19vxoCovkQAvD_BwE:G:s&amp;s_kwcid=AL!4422!3!651542249938!e!!g!!aws%20lambda!19835810591!150095231954">AWS Lambda</a>: A serverless compute service that runs your code in response to events and automatically manages the underlying compute resources for you. It allows you to run code without provisioning or managing servers.</p>

<ul>
  <li>
    <p><a href="https://aws.amazon.com/ecr/">Amazon ECR</a>: A fully-managed container registry that makes it easy for developers to store, manage, and deploy Docker container images. Itâ€™s integrated with Amazon ECS and AWS Fargate, simplifying your development to production workflow.</p>
  </li>
  <li><a href="https://www.docker.com/">Docker</a>: A platform that uses containerization to package up an application with all of the parts it needs, such as libraries and other dependencies, and ship it all out as one package. This ensures that the application runs quickly and reliably on any server.
    <blockquote>
      <p>Dowload Link: <a href="https://www.docker.com/products/docker-desktop/">https://www.docker.com/products/docker-desktop/</a></p>
    </blockquote>
  </li>
  <li><a href="https://www.langchain.com/">LangChain</a>: A framework for building and deploying language models, providing tools for document loading, vector storage, embeddings, and more. Itâ€™s used here to facilitate the deployment of the RAG model.</li>
</ul>

<h2 id="integration-and-deployment-steps">Integration and Deployment Steps</h2>

<ol>
  <li><strong>Prepare Your Environment:</strong> Ensure you have the AWS CLI installed and configured, Docker installed, and Python 3.11 or later installed and configured. Youâ€™ll also need an active AWS account with the necessary permissions.
    <blockquote>
      <p>Download Link: <a href="https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html">https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html</a></p>
    </blockquote>
  </li>
  <li>
    <p><strong>Create a Dockerfile:</strong> This file defines the environment in which your Lambda function will run. It starts from a base image provided by AWS (<em><code class="language-plaintext highlighter-rouge">public.ecr.aws/lambda/python:3.12</code></em>) and copies your application code and dependencies into the image. It also installs any necessary Python packages from a <code class="language-plaintext highlighter-rouge">requirements.txt</code> file as below:</p>

    <p>langchain_community
 boto3==1.34.37
 numpy
 langchain
 langchainhub
 langchain-openai
 chromadb
 bs4
 tiktoken
 openai</p>
  </li>
</ol>

<div class="language-docker highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="c"># Use the AWS base image for Python 3.12</span>
    FROM public.ecr.aws/lambda/python:3.12
    
    <span class="c"># Install build-essential to get the C++ compiler and other necessary tools</span>
    RUN microdnf update -y &amp;&amp; microdnf install -y gcc-c++ make
    
    <span class="c"># Copy requirements.txt</span>
    COPY requirements.txt ${LAMBDA_TASK_ROOT}
    
    # Install the specified packages
    RUN pip install -r requirements.txt
    
    <span class="c"># Copy function code</span>
    COPY lambda_function.py ${LAMBDA_TASK_ROOT}
    
    # Set the permissions to make the file executable
    RUN chmod +x lambda_function.py
    
    <span class="c"># Set the CMD to your handler</span>
    CMD [ "lambda_function.lambda_handler" ]
</code></pre></div></div>

<ol>
  <li>
    <p><strong>Build and Push Your Docker Image to Amazon ECR:</strong> Use the AWS CLI to create a repository in ECR, build your Docker image, and push it to the repository. This step requires permissions to interact with ECR and S3.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  aws ecr create-repository - repository-name my-rag-lambda
  docker build <span class="nt">-t</span> my-test-lambda <span class="nb">.</span>
  docker tag my-rag-lambda:latest &lt;aws_account_id&gt;.dkr.ecr.&lt;region&gt;.amazonaws.com/my-test-lambda:latest
  docker push &lt;aws_account_id&gt;.dkr.ecr.&lt;region&gt;.amazonaws.com/my-test-lambda:latest
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>Create a Lambda Function</strong>: In the AWS Lambda console, create a new function using the container image option. Specify the URI of the image in ECR as the image source.</p>
  </li>
  <li>
    <p><strong>Configure Your Lambda Function</strong>: Set the necessary environment variables, such as <code class="language-plaintext highlighter-rouge">OPENAI_API_KEY</code> for LangChain, and configure any other settings as needed.</p>
  </li>
  <li>
    <p><strong>Test Your Lambda Function</strong>: Invoke your Lambda function to test it. You can do this from the AWS Lambda console or using the AWS CLI. Ensure that the function is correctly processing inputs and generating outputs as expected.</p>
  </li>
</ol>

<h2 id="implementation">Implementation</h2>

<p>Below code is designed to deploy a Retrieval-Augmented Generation (RAG) model using AWS Lambda, Docker, and Amazon ECR, with LangChain for language model deployment.</p>

<h3 id="environment-setup">Environment Setup</h3>

<p>First, imports necessary libraries and sets up the environment:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import boto3
import bs4
from langchain import hub
from langchain_community.document_loaders import WebBaseLoader
from langchain_community.vectorstores import Chroma
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.chat_models import ChatOpenAI
from langchain_text_splitters import RecursiveCharacterTextSplitter
import os
# Retrieve the OpenAI API key from environment variables
OPENAI_API_KEY = os.environ['OPENAI_API_KEY']
print(OPENAI_API_KEY)
</code></pre></div></div>

<ul>
  <li>boto3: The AWS SDK for Python, allowing Python developers to write software that makes use of services like Amazon S3, Amazon EC2, and others.</li>
  <li>bs4: Beautiful Soup, a library for pulling data out of HTML and XML files.</li>
  <li>LangChain: A framework for building and deploying language models, providing tools for document loading, vector storage, embeddings, and more.</li>
  <li>Environment Variables: The code retrieves the <code class="language-plaintext highlighter-rouge">OPENAI_API_KEY</code> from the environment variables, which is crucial for accessing OpenAIâ€™s API.</li>
</ul>

<h3 id="data-loading-and-processing">Data Loading and Processing</h3>

<p>The <code class="language-plaintext highlighter-rouge">load_data</code> function is responsible for loading, chunking, and indexing the contents of a web page:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def load_data():
 loader = WebBaseLoader(
 web_paths=("https://lilianweng.github.io/posts/2023-06-23-agent/",),
 bs_kwargs=dict(
 parse_only=bs4.SoupStrainer(
 class_=("post-content", "post-title", "post-header")
 )
 ),
 )
 docs = loader.load()
 text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
 splits = text_splitter.split_documents(docs)
 vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())
 retriever = vectorstore.as_retriever()
 return retriever
</code></pre></div></div>

<ul>
  <li>WebBaseLoader: Loads documents from web paths, using Beautiful Soup to parse and extract specific elements.</li>
  <li>RecursiveCharacterTextSplitter: Splits documents into chunks based on character count and overlap.</li>
  <li>Chroma: Creates a vector store from the split documents, using OpenAI embeddings for vectorization.</li>
  <li>Retriever: A retriever object that can be used to retrieve relevant documents based on queries.</li>
</ul>

<h3 id="response-generation">Response Generation</h3>

<p>The <code class="language-plaintext highlighter-rouge">get_response</code> function generates a response to a given query using the RAG model:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def get_response(query):
 prompt = hub.pull("rlm/rag-prompt")
 llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)
 retriever = load_data()
 rag_chain = (
 {"context": retriever | format_docs, "question": RunnablePassthrough()}
 | prompt
 | llm
 | StrOutputParser()
 )
 return rag_chain.invoke(query)
</code></pre></div></div>

<ul>
  <li>hub.pull: Retrieves a prompt from <a href="https://smith.langchain.com/hub/rlm/rag-prompt">LangChainâ€™s hub</a>.</li>
  <li>ChatOpenAI: Initializes a chat model with GPT-3.5 Turbo.</li>
  <li>RunnablePassthrough: A component that passes the input directly to the next component in the chain.</li>
  <li>StrOutputParser: Parses the output of the RAG model into a string format.</li>
</ul>

<h3 id="aws-lambda-handler">AWS Lambda Handler</h3>

<p>Finally, the <code class="language-plaintext highlighter-rouge">lambda_handler</code> function is the entry point for AWS Lambda, which receives an event and context, processes the query, and returns a response:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def lambda_handler(event, context):
 query = event.get("question")
 response = get_response(query)
 print("response:", response)
 return {"body": response, "statusCode": 200}
</code></pre></div></div>

<ul>
  <li>
    <p>Event and Context: AWS Lambda passes an event object and a context object to the handler. The event object contains information about the triggering event, and the context object contains information about the runtime environment.</p>
  </li>
  <li>
    <p>Query Processing: The function extracts the query from the event, generates a response using the <code class="language-plaintext highlighter-rouge">get_response</code> function, and prints the response and returns a response object containing the generated response and a status code of 200, indicating success.</p>
  </li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>Deploying a RAG model in AWS Lambda using Docker and ECR with LangChain involves preparing your environment, creating a Dockerfile, building and pushing your Docker image to ECR, creating a Lambda function, configuring it, and testing it. This process leverages the serverless capabilities of AWS Lambda, the containerization benefits of Docker, and the language model deployment capability provided by LangChain.</p>

<blockquote>
  <p><strong>Connect with me on <a href="https://www.linkedin.com/in/aboniasojasingarayar/">Linkedin</a></strong></p>
</blockquote>

<blockquote>
  <p><strong>Find me on <a href="https://github.com/Abonia1">Github</a></strong></p>
</blockquote>

<blockquote>
  <p><strong>Visit my technical channel on <a href="https://www.youtube.com/@AboniaSojasingarayar">Youtube</a></strong></p>
</blockquote>

<blockquote>
  <p><strong>Support: <a href="https://www.buymeacoffee.com/abonia">Buy me a Cofee/Chai</a></strong></p>
</blockquote>

<blockquote>
  <h1 id="thanks-for-reading"><em>Thanks for Reading!</em></h1>
</blockquote>]]></content><author><name>Abonia Sojasingarayar</name><email>aboniaa@gmail.com</email></author><category term="blogs" /><summary type="html"><![CDATA[Deploying a RAG (Retrieval-Augmented Generation) application in AWS Lambda using Docker and Amazon Elastic Container Registry (ECR) with LangChain.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/img/blog/aws-rag.webp" /><media:content medium="image" url="http://localhost:4000/assets/img/blog/aws-rag.webp" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>
<!DOCTYPE html>
<html lang="en"><!--
 __  __                __                                     __
/\ \/\ \              /\ \             __                    /\ \
\ \ \_\ \   __  __    \_\ \      __   /\_\      __       ___ \ \ \/'\
 \ \  _  \ /\ \/\ \   /'_` \   /'__`\ \/\ \   /'__`\    /'___\\ \ , <
  \ \ \ \ \\ \ \_\ \ /\ \L\ \ /\  __/  \ \ \ /\ \L\.\_ /\ \__/ \ \ \\`\
   \ \_\ \_\\/`____ \\ \___,_\\ \____\ _\ \ \\ \__/.\_\\ \____\ \ \_\ \_\
    \/_/\/_/ `/___/> \\/__,_ / \/____//\ \_\ \\/__/\/_/ \/____/  \/_/\/_/
                /\___/                \ \____/
                \/__/                  \/___/

Powered by Hydejack v9.1.6 <https://hydejack.com/>
-->







<head>
  




  <meta name="robots" content="noindex">



  
    
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Multi-Modal Retrieval - Bridging Text and Images with BGE and CLIP | Abonia Sojasingarayar</title>
<meta name="generator" content="Jekyll v4.3.3" />
<meta property="og:title" content="Multi-Modal Retrieval - Bridging Text and Images with BGE and CLIP" />
<meta name="author" content="Abonia Sojasingarayar" />
<meta property="og:locale" content="en" />
<meta name="description" content="In today’s data-rich world, being able to retrieve relevant information across different modalities (text, images, audio) has become increasingly important. This post will guide you through creating a multi-modal retrieval system that combines text embeddings from BGE (Bidirectional Generative Encoder) and image embeddings from CLIP (Contrastive Language-Instrumental Pre-training) to index and query Wikipedia articles." />
<meta property="og:description" content="In today’s data-rich world, being able to retrieve relevant information across different modalities (text, images, audio) has become increasingly important. This post will guide you through creating a multi-modal retrieval system that combines text embeddings from BGE (Bidirectional Generative Encoder) and image embeddings from CLIP (Contrastive Language-Instrumental Pre-training) to index and query Wikipedia articles." />
<link rel="canonical" href="http://localhost:4000/blogs/2024-10-01-Multi-Modal-Retrieval-BGE-CLIP/" />
<meta property="og:url" content="http://localhost:4000/blogs/2024-10-01-Multi-Modal-Retrieval-BGE-CLIP/" />
<meta property="og:site_name" content="Abonia Sojasingarayar" />
<meta property="og:image" content="http://localhost:4000/assets/img/blog/Multi-ModalRetriever.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-10-01T00:00:00+02:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="http://localhost:4000/assets/img/blog/Multi-ModalRetriever.png" />
<meta property="twitter:title" content="Multi-Modal Retrieval - Bridging Text and Images with BGE and CLIP" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Abonia Sojasingarayar"},"dateModified":"2024-09-25T15:43:26+02:00","datePublished":"2024-10-01T00:00:00+02:00","description":"In today’s data-rich world, being able to retrieve relevant information across different modalities (text, images, audio) has become increasingly important. This post will guide you through creating a multi-modal retrieval system that combines text embeddings from BGE (Bidirectional Generative Encoder) and image embeddings from CLIP (Contrastive Language-Instrumental Pre-training) to index and query Wikipedia articles.","headline":"Multi-Modal Retrieval - Bridging Text and Images with BGE and CLIP","image":"http://localhost:4000/assets/img/blog/Multi-ModalRetriever.png","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/blogs/2024-10-01-Multi-Modal-Retrieval-BGE-CLIP/"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/img/blog/logo.jpeg"},"name":"Abonia Sojasingarayar"},"url":"http://localhost:4000/blogs/2024-10-01-Multi-Modal-Retrieval-BGE-CLIP/"}</script>
<!-- End Jekyll SEO tag -->


  

  



  <meta name="theme-color" content="rgb(25,55,71)">


<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta http-equiv="x-ua-compatible" content="ie=edge">

<meta name="mobile-web-app-capable" content="yes">

<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-title" content="Abonia Sojasingarayar">
<meta name="apple-mobile-web-app-status-bar-style" content="default">

<meta name="application-name" content="Abonia Sojasingarayar">

<meta name="generator" content="Hydejack v9.1.6" />


<link rel="alternate" href="http://localhost:4000/blogs/2024-10-01-Multi-Modal-Retrieval-BGE-CLIP/" hreflang="en">

<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Abonia Sojasingarayar" />


<link rel="shortcut icon"    href="/assets/img/favicon.ico">
<link rel="apple-touch-icon" href="/assets/icons/icon-192x192.png">

<link rel="manifest" href="/assets/site.webmanifest">

<link rel="dns-prefetch" href="https://fonts.googleapis.com"><link rel="dns-prefetch" href="https://fonts.gstatic.com">



<link rel="preload" href="/assets/img/swipe.svg" as="image" id="_hrefSwipeSVG">






<script>!function(r,c){"use strict";function a(e,t,n,o){e.addEventListener?e.addEventListener(t,n,o):e.attachEvent?e.attachEvent("on"+t,n):e["on"+t]=n}r.loadJS=function(e,t){var n=c.createElement("script"),e=(n.src=e,t&&a(n,"load",t,{once:!0}),c.scripts[0]);return e.parentNode.insertBefore(n,e),n},r._loaded=!1,r.loadJSDeferred=function(e,t){var n=c.createElement("script");function o(){r._loaded=!0,t&&a(n,"load",t,{once:!0});var e=c.scripts[0];e.parentNode.insertBefore(n,e)}return n.src=e,r._loaded?o():a(r,"load",o,{once:!0}),n},r.setRel=r.setRelStylesheet=function(e){a(c.getElementById(e),"load",function(){this.rel="stylesheet"},{once:!0})}}(window,document);
!function(a){"use strict";var b=function(b,c,d){function e(a){return h.body?a():void setTimeout(function(){e(a)})}function f(){i.addEventListener&&i.removeEventListener("load",f),i.media=d||"all"}var g,h=a.document,i=h.createElement("link");if(c)g=c;else{var j=(h.body||h.getElementsByTagName("head")[0]).childNodes;g=j[j.length-1]}var k=h.styleSheets;i.rel="stylesheet",i.href=b,i.media="only x",e(function(){g.parentNode.insertBefore(i,c?g:g.nextSibling)});var l=function(a){for(var b=i.href,c=k.length;c--;)if(k[c].href===b)return a();setTimeout(function(){l(a)})};return i.addEventListener&&i.addEventListener("load",f),i.onloadcssdefined=l,l(f),i};"undefined"!=typeof exports?exports.loadCSS=b:a.loadCSS=b}("undefined"!=typeof global?global:this);
!function(a){if(a.loadCSS){var b=loadCSS.relpreload={};if(b.support=function(){try{return a.document.createElement("link").relList.supports("preload")}catch(b){return!1}},b.poly=function(){for(var b=a.document.getElementsByTagName("link"),c=0;c<b.length;c++){var d=b[c];"preload"===d.rel&&"style"===d.getAttribute("as")&&(a.loadCSS(d.href,d,d.getAttribute("media")),d.rel=null)}},!b.support()){b.poly();var c=a.setInterval(b.poly,300);a.addEventListener&&a.addEventListener("load",function(){b.poly(),a.clearInterval(c)}),a.attachEvent&&a.attachEvent("onload",function(){a.clearInterval(c)})}}}(this);
!function(w) {
  w._baseURL = '/';
  w._publicPath = '/assets/js/';
  w._noPushState = false;
  w._noDrawer = false;
  w._noNavbar = false;
  w._noToc = false;
  w._noSearch = false;
  w._search = {
    DATA_URL: '/assets/sitedata.json?no-cache',
    STORAGE_KEY: 'mini-search/',
    INDEX_KEY: 'index--2025-01-05T15:36:45+01:00',
  };
  w._clapButton = true;
}(window);</script>


<script async src="/assets/bower_components/MathJax/es5/tex-mml-chtml.js" id="_MathJax"></script>


<!--[if gt IE 8]><!---->

  




<link rel="stylesheet" href="/assets/css/hydejack-9.1.6.css" id="_stylePreload">
<link rel="stylesheet" href="/assets/icomoon/style.css" id="_iconsPreload">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Slab:700%7CNoto+Sans:400,400i,700,700i&display=swap" id="_fontsPreload">



  <style id="_pageStyle">

html{--accent-color: rgb(79,177,186);--accent-color-faded: rgba(79, 177, 186, 0.5);--accent-color-highlight: rgba(79, 177, 186, 0.1);--accent-color-darkened: #409ba3;--theme-color: rgb(25,55,71)}
</style>


<!--<![endif]-->




</head>

<body class="no-break-layout">
  


<hy-push-state
  id="_pushState"
  replace-selector="#_main"
  link-selector="a[href]:not([href^='/assets/']):not(.external):not(.no-push-state)"
  script-selector="script"
  duration="500"
  hashchange
>
  
  
  <div id="_navbar" class="navbar fixed-top">
  <div class="content">
    <span class="sr-only">Jump to:</span>
    <div class="nav-btn-bar">
      <a id="_menu" class="nav-btn no-hover" href="#_drawer--opened">
        <span class="sr-only">Navigation</span>
        <span class="icon-menu"></span>
      </a>
      <div class="nav-span"></div>
    </div>
  </div>
</div>
<hr class="sr-only" hidden />

  <main
  id="_main"
  class="content layout-post"
  role="main"
>
  <nav id="breadcrumbs" class="screen-only"><ul>
  
  
    <li><a href="/">home</a></li>
    
      <li>
        
          <span>/</span>
          
          
          <a href="/blogs/">blogs</a>
        
      </li>
    
      <li>
        
          <span>/</span>
          <span>2024-10-01-Multi-Modal-Retrieval-BGE-CLIP</span>
        
      </li>
    
  
</ul></nav>
  










<article id="post-blogs-Multi-Modal-Retrieval-BGE-CLIP" class="page post mb6" role="article">
  <header>
    <h1 class="post-title flip-project-title">
      
        Multi-Modal Retrieval - Bridging Text and Images with BGE and CLIP
      
    </h1>

    <div class="post-date">
      
      <span class="ellipsis mr1">
        <time datetime="2024-10-01T00:00:00+02:00">01 Oct 2024</time> in <a href="/example/" class="flip-title">Blogs</a> 
      </span>
      
        
          
          
          
            
            
            <span class="ellipsis" data-tippy-content="Last modified at: 25 Sep 2024">
              <span class="sr-only">Last modified at:</span>
              <span class="icon-history"></span>
              <time datetime="2024-09-25T15:43:26+02:00">2024-09-25</time>
            </span>
          
        
      
    </div>

    
    
      
        <div class="img-wrapper lead aspect-ratio sixteen-nine flip-project-img">
          


<img
  
    src="/assets/img/blog/Multi-ModalRetriever.png"
    
    
  
  alt="Multi-Modal Retrieval - Bridging Text and Images with BGE and CLIP"
  
  
  width="864"
  height="486"
  loading="lazy"
/>

        </div>
      
      
    

    



  
    <p class="note-sm" >
      In today’s data-rich world, being able to retrieve relevant information across different modalities (text, images, audio) has become increasingly important. This post will guide you through creating a multi-modal retrieval system that combines text embeddings from BGE (Bidirectional Generative Encoder) and image embeddings from CLIP (Contrastive Language-Instrumental Pre-training) to index and query Wikipedia articles.

    </p>
  


  </header>

  
    <p><strong><a href="https://youtu.be/9oogZrSTiM0?si=epr5kNKcrbzeZ52z">Link to the complete hands-on tutorial on Multi-Modal Retrieval - Bridging Text and Images with BGE and CLIP</a></strong></p>

<p><strong>Reading_time:</strong> 5 min<br />
  <strong>Tags:</strong> [MultimodalRetrieval, AI, MachineLearning, NLP, ComputerVision, CLIP, BGE, ArtificialIntelligence, CrossModalSearch, TextEmbedding, ImageEmbedding, VectorSearch]</p>
<ul class="large-only" id="markdown-toc">
  <li><a href="#multi-modal-retrieval-bridging-text-and-images-with-bge-and-clip" id="markdown-toc-multi-modal-retrieval-bridging-text-and-images-with-bge-and-clip">Multi-Modal Retrieval: Bridging Text and Images with BGE and CLIP</a>    <ul>
      <li><a href="#building-and-testing-a-multi-modal-retriever--hands-on" id="markdown-toc-building-and-testing-a-multi-modal-retriever--hands-on">Building and Testing a Multi-Modal Retriever — Hands-On</a></li>
    </ul>
  </li>
  <li><a href="#understanding-multi-modal-retrieval" id="markdown-toc-understanding-multi-modal-retrieval">Understanding Multi-Modal Retrieval</a>    <ul>
      <li><a href="#technical-overview" id="markdown-toc-technical-overview">Technical Overview</a></li>
      <li><a href="#data-preparation" id="markdown-toc-data-preparation">Data Preparation</a></li>
      <li><a href="#building-the-vector-store" id="markdown-toc-building-the-vector-store">Building the Vector Store</a></li>
      <li><a href="#query-processing-and-retrieval" id="markdown-toc-query-processing-and-retrieval">Query Processing and Retrieval</a></li>
    </ul>
  </li>
  <li><a href="#tutorial" id="markdown-toc-tutorial">Tutorial</a></li>
  <li><a href="#colab-notebook" id="markdown-toc-colab-notebook">Colab Notebook</a></li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
</ul>

<h2 id="multi-modal-retrieval-bridging-text-and-images-with-bge-and-clip">Multi-Modal Retrieval: Bridging Text and Images with BGE and CLIP</h2>

<h3 id="building-and-testing-a-multi-modal-retriever--hands-on">Building and Testing a Multi-Modal Retriever — Hands-On</h3>

<p>In today’s data-rich world, being able to retrieve relevant information across different modalities (text, images, audio) has become increasingly important. This post will guide you through creating a multi-modal retrieval system that combines text embeddings from BGE (Bidirectional Generative Encoder) and image embeddings from CLIP (Contrastive Language-Instrumental Pre-training) to index and query Wikipedia articles.</p>

<iframe width="900" height="500" src="https://www.youtube.com/embed/9oogZrSTiM0" frameborder="0" allowfullscreen=""></iframe>

<p>In the rapidly evolving landscape of artificial intelligence and natural language processing, the ability to seamlessly integrate text and image information has become increasingly crucial. This article explores a cutting-edge approach to achieving this integration, leveraging state-of-the-art techniques to create a powerful demonstration of cross-modal retrieval capabilities.</p>

<h2 id="understanding-multi-modal-retrieval">Understanding Multi-Modal Retrieval</h2>

<p>Multi-modal retrieval allows us to search for information based on multiple types of input, such as text queries and image queries. It’s particularly useful for applications like visual search, content-based recommendation systems, and multimedia analysis.</p>

<p>Key aspects of multi-modal retrieval include:</p>

<ul>
  <li>
    <p>Indexing: Creating embeddings for both text and image data</p>
  </li>
  <li>
    <p>Querying: Processing user inputs and finding similar matches</p>
  </li>
  <li>
    <p>Ranking: Ordering results based on relevance</p>
  </li>
</ul>

<h3 id="technical-overview">Technical Overview</h3>

<p>The proposed system utilizes several advanced techniques to enable efficient and accurate retrieval of both textual and visual content:</p>

<ol>
  <li>
    <p>Text Embedding Index: 
 — Utilizes BAAI/bge-small-en-v1.5 for text representation
 — Employs Hugging Face (HF) embedding for query encoding</p>
  </li>
  <li>
    <p>Image Embedding Index:
 — Implements CLIP embeddings from sentence transformers
 — Leverages CLIP embedding for image query encoding</p>
  </li>
  <li>
    <p>Query Encoder:
 — Processes text queries using HF embedding
 — Processes image queries using CLIP embedding</p>
  </li>
  <li>
    <p>Framework:
 — Built on top of LlamaIndex for efficient vector storage and retrieval</p>
  </li>
</ol>

<h3 id="data-preparation">Data Preparation</h3>

<p>Before implementing the retrieval system, a crucial step involves preparing the necessary datasets:</p>

<ul>
  <li>Download raw text and image files for Wikipedia articles</li>
  <li>These files serve as the foundation for building comprehensive indexes</li>
</ul>

<h3 id="building-the-vector-store">Building the Vector Store</h3>

<p>With the data at hand, the next step is to construct the vector store:</p>

<ol>
  <li>
    <p>Text Index Construction:
 — Apply BAAI/bge-small-en-v1.5 embeddings to text data
 — Create a vector store using these embeddings</p>
  </li>
  <li>
    <p>Image Index Construction:
 — Generate CLIP embeddings for image data
 — Build a separate vector store for the image embeddings</p>
  </li>
</ol>

<h3 id="query-processing-and-retrieval">Query Processing and Retrieval</h3>

<p>Once the vector store is populated, the system can handle various types of queries:</p>

<ol>
  <li>
    <p>Text Queries:
 — Encode input text using HF embedding
 — Search the text index for relevant matches</p>
  </li>
  <li>
    <p>Image Queries:
 — Extract features from input images using CLIP embedding
 — Search the image index for visually similar content</p>
  </li>
  <li>
    <p>Cross-Modal Queries:
 — Combine text and image queries for simultaneous retrieval
 — Leverage the power of both indices to find relevant information</p>
  </li>
</ol>

<h2 id="tutorial">Tutorial</h2>

<p>A user searches for “Bat man” using a combination of text and image queries. The system would:</p>

<ol>
  <li>Process the text query using HF embedding</li>
  <li>Retrieve relevant Wikipedia articles from the text index</li>
  <li>Simultaneously process the image query (e.g., a photo of Mars, Batman)</li>
  <li>Find visually similar images from the image index</li>
  <li>Return a combined result set that includes both textually and visually relevant information</li>
</ol>

<p>This tutorial highlights the system’s ability to bridge the gap between linguistic and visual representations, providing users with a comprehensive understanding of complex topics through multimodal retrieval.</p>

<h2 id="colab-notebook">Colab Notebook</h2>

<p><strong><a href="https://github.com/Abonia1/Multi-Modal-Retriever/blob/main/multi_modal_retrieval.ipynb">Link to the complete Notebook</a></strong></p>

<script src="https://gist.github.com/Abonia1/a0c555f6e53bc271fe305d29983af645.js"></script>

<p><img src="https://cdn-images-1.medium.com/max/2360/1*xkAvz-IDGh9MVxcx7MBkXA.png" alt="" /></p>

<h2 id="conclusion">Conclusion</h2>

<p>By integrating cutting-edge text and image embedding techniques within a unified framework, this system offers a powerful tool for information retrieval across modalities. Its potential applications extend beyond simple demonstrations, potentially revolutionizing how we interact with and understand complex information in various domains such as education, research, and entertainment. As AI technology continues to advance, such systems will play an increasingly important role in facilitating human-computer interaction and knowledge acquisition.</p>

<p>Lets learn and grow together!</p>

<hr />
<p><strong><em>Thanks for Reading!</em></strong></p>

<p><strong><a href="https://abonia1.github.io/">Website/Newletter</a></strong>
<strong><a href="https://aboniasojasingarayar.substack.com">AIMagazine Substack</a></strong></p>

<p>Connect with me on <strong><a href="https://www.linkedin.com/in/aboniasojasingarayar/">Linkedin</a></strong></p>

<p>Find me on <strong><a href="https://github.com/Abonia1">Github</a></strong></p>

<p>Visit my technical channel on <strong><a href="https://www.youtube.com/@AboniaSojasingarayar">Youtube</a></strong></p>

<p>Support: <strong><a href="https://www.buymeacoffee.com/abonia">Buy me a Cofee/Chai</a></strong></p>

  
</article>



  <hr class="dingbat related mb6" />






  
     


  <aside class="about related mt4 mb4" role="complementary">
    
    

<div class="author mt4">
  

  
    


<img
  
    src="/assets/img/blog/logo.jpeg"
    srcset="https://via.placeholder.com/128x128 1x,/assets/img/blog/logo.jpeg 2x"
    
  
  alt="Abonia Sojasingarayar"
  class="avatar"
  
  width="120"
  height="120"
  loading="lazy"
/>

  

  
  
  <h2  class="page-title hr-bottom">
    About
  </h2>

  <p>I am distinguished Machine Learning Scientist, Data Scientist, Large Language Model Engineer, NLP Engineer, and Technical Book Reviewer, holds a Masters degree in Artificial Intelligence and boasts over 7 years of experience. With a robust background in crafting and implementing ML systems across diverse domains, including cybersecurity, banking, transit,cosmetics &amp; hygiene research, and e-commerce. Find me on Medium, Google Scholar, GitHub, and LinkedIn, where I mentors others and communicates complex solutions effectively.</p>


  <div class="sidebar-social">
    <span class="sr-only">Social:</span>
<ul>
  
    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://www.linkedin.com/in/aboniasojasingarayar" title="LinkedIn" class="no-mark-external">
      <span class="icon-linkedin2"></span>
      <span class="sr-only">LinkedIn</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://github.com/Abonia1" title="GitHub" class="no-mark-external">
      <span class="icon-github"></span>
      <span class="sr-only">GitHub</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://medium.com/@abonia" title="medium" class="no-mark-external">
      <span class="icon-link"></span>
      <span class="sr-only">medium</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://www.youtube.com/channel/UCGphGM_oeR4r9dqVs71Jc5w" title="YouTube" class="no-mark-external">
      <span class="icon-youtube"></span>
      <span class="sr-only">YouTube</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://twitter.com/AboniaJesse" title="Twitter" class="no-mark-external">
      <span class="icon-twitter"></span>
      <span class="sr-only">Twitter</span>
    </a>
  </li>


    
  
</ul>

  </div>
</div>

  </aside>


  

  
  

  
    


  <aside class="related mb4" role="complementary">  <h2 class="hr-bottom">Related Posts</h2>  <ul class="related-posts">                  <li class="h4">  <a href="/blogs/2025-01-01-Join-the-Community-AI-Machine-Learning-ComputerVision-Data-Science-GenAI-NLP-MLOps-LLMOps/" class="flip-title"><span>Join the Community in AI, ML, Data Science, ,Computer Vision, Data Science, GenAI, NLP, MLOps,  LLMOps – Let’s Learn Together</span></a>  <time class="faded fine" datetime="2025-01-01T00:00:00+01:00">01 Jan 2025</time></li>                        <li class="h4">  <a href="/blogs/2024-12-02-Deploy-and-Automate-ML-Workflow-GitHub-Actions-and-CML-for-CICD/" class="flip-title"><span>Automate ML and LLM Workflow with GitHub Actions & CML</span></a>  <time class="faded fine" datetime="2024-12-02T00:00:00+01:00">02 Dec 2024</time></li>                        <li class="h4">  <a href="/blogs/2024-10-05-SAM2-Fine-Tuning-Custom-Dataset/" class="flip-title"><span>SAM 2 Advanced Object Segmentation for Images and Videos</span></a>  <time class="faded fine" datetime="2024-10-05T00:00:00+02:00">05 Oct 2024</time></li>            </ul></aside>

  

  
  

  
    

  


  
<footer class="content" role="contentinfo">
  <hr/>
  
    <p><small class="copyright">© 2024. All rights reserved.
</small></p>
  
  
    <nav class="legal"><small>
    
      
      <a class="heading flip-title" href="/LICENSE/">LICENSE</a>
      
    
    </small></nav>
  
    <p><small>Powered by <a class="external" href="https://hydejack.com/">Hydejack</a> v<span id="_version">9.1.6</span></small></p>
  <hr class="sr-only"/>
</footer>


</main>

  <hy-drawer
  id="_drawer"
  class=""
  side="left"
  threshold="10"
  noscroll
  
>
  <header id="_sidebar" class="sidebar" role="banner">
    




<div class="sidebar-bg sidebar-overlay" style="background-color:rgb(25,55,71);background-image:url(/assets/img/sidebar-bg.jpg)"></div>

    <div class="sidebar-sticky">
  <div class="sidebar-about">
    
      <a class="no-hover" href="/" tabindex="-1">
        <img src="/assets/img/blog/logo.jpeg" class="avatar" alt="Abonia Sojasingarayar" width="120" height="120" loading="lazy" />
      </a>
    
    <a class="sidebar-title" href="/"><h2 class="h1">Abonia Sojasingarayar</h2></a>
    
    
      <p class="">
        <table>
  <tbody>
    <tr>
      <td>4x Linkedin Top Voice</td>
      <td>Machine Learning, DS &amp; MLOps</td>
      <td>Author</td>
    </tr>
  </tbody>
</table>

      </p>
    
  </div>

  <nav class="sidebar-nav heading" role="navigation">
    <span class="sr-only">Navigation:</span>
<ul>
  
    
      
      <li>
        <a
          id="_drawer--opened"
          href="/example/"
          class="sidebar-nav-item "
          
        >
          Blogs
        </a>
      </li>
    
      
      <li>
        <a
          
          href="/about/"
          class="sidebar-nav-item "
          
        >
          About
        </a>
      </li>
    
      
      <li>
        <a
          
          href="/newsletter/"
          class="sidebar-nav-item "
          
        >
          Newsletter
        </a>
      </li>
    
      
      <li>
        <a
          
          href="https://aboniasojasingarayar.substack.com/"
          class="sidebar-nav-item "
          
        >
          AI Magazine
        </a>
      </li>
    
  
</ul>

  </nav>

  
  <div class="sidebar-social">
    <span class="sr-only">Social:</span>
<ul>
  
    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://www.linkedin.com/in/aboniasojasingarayar" title="LinkedIn" class="no-mark-external">
      <span class="icon-linkedin2"></span>
      <span class="sr-only">LinkedIn</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://github.com/Abonia1" title="GitHub" class="no-mark-external">
      <span class="icon-github"></span>
      <span class="sr-only">GitHub</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://medium.com/@abonia" title="medium" class="no-mark-external">
      <span class="icon-link"></span>
      <span class="sr-only">medium</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://www.youtube.com/channel/UCGphGM_oeR4r9dqVs71Jc5w" title="YouTube" class="no-mark-external">
      <span class="icon-youtube"></span>
      <span class="sr-only">YouTube</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://twitter.com/AboniaJesse" title="Twitter" class="no-mark-external">
      <span class="icon-twitter"></span>
      <span class="sr-only">Twitter</span>
    </a>
  </li>


    
  
</ul>

  </div>
</div>
  </header>
</hy-drawer>
<hr class="sr-only" hidden />

</hy-push-state>


  <!--[if gt IE 10]><!---->
  <script nomodule>!function(){var t,n=document.createElement("script");!("noModule"in n)&&"onbeforeload"in n&&(t=!1,document.addEventListener("beforeload",function(e){if(e.target===n)t=!0;else if(!e.target.hasAttribute("nomodule")||!t)return;e.preventDefault()},!0),n.type="module",n.src=".",document.head.appendChild(n),n.remove())}();
</script>
  <script src="/assets/js/hydejack-9.1.6.js" type="module"></script>
  <script src="/assets/js/LEGACY-hydejack-9.1.6.js" nomodule defer></script>
  

  

<!--<![endif]-->
  <!-- <script>
  document.querySelector('hy-push-state').setAttribute('prefetch', '');

  document.querySelectorAll('.sidebar a[href^="/"]').forEach(function (el) { 
    el.addEventListener('click', function (e) {
      if (el.pathname === window.location.pathname) {
        e.preventDefault();
        e.stopPropagation();
        document.querySelector('hy-drawer').close();
      }
    });
  });
</script> -->

<!--
Code for integrating CloudFlare's email protection with Hydejack's single page app loading.
-->
<script>
  document.getElementById('_pushState').addEventListener('hy-push-state-after', function (e) {
    function e(e){
      (console.error?console.error:console.log).call(console,e)
    }

    function t(e){
      return l.innerHTML='<a href="'+e.replace(/"/g,"&quot;")+'"></a>',l.childNodes[0].getAttribute("href")
    }

    function r(e,t){
      var r=e.substr(t,2);return parseInt(r,16)
    }

    function n(e,n){
      for(var o="",c=r(e,n),a=n+2;a<e.length;a+=2){
        var l=r(e,a)^c;
        o+=String.fromCharCode(l)
      }
      return t(o)
    }

    var o="/cdn-cgi/l/email-protection#",
        c=".__cf_email__",
        a="data-cfemail",
        l=document.createElement("div");

    !function(){
      for(var t=document.getElementsByTagName("a"),r=0;r<t.length;r++)
        try{
          var c=t[r],a=c.href.indexOf(o);
          a>-1&&(c.href="mailto:"+n(c.href,a+o.length))
        }catch(t){
          e(t)
        }
    }(),
    function(){
      for(var t=document.querySelectorAll(c),r=0;r<t.length;r++)
        try{
          var o=t[r],l=n(o.getAttribute(a),0),i=document.createTextNode(l);
          o.parentNode.replaceChild(i,o)
        }catch(t){
          e(t)
        }
    }()
  });
</script>





<div hidden>
  
  <h2 class="sr-only">Templates (for web app):</h2>

  <template id="_animation-template">
  <div class="animation-main fixed-top">
    <nav id="breadcrumbs" class="screen-only"><ul>
  
  
</ul></nav>
    <div class="content">
      <div class="page"></div>
    </div>
  </div>
</template>

  <template id="_loading-template">
  <div class="loading nav-btn fr">
    <span class="sr-only">Loading…</span>
    <span class="icon-cog"></span>
  </div>
</template>

  <template id="_error-template">
  <div class="page">
    <h1 class="page-title">Error</h1>
    
    
    <p class="lead">
      Sorry, an error occurred while loading <a class="this-link" href=""></a>.

    </p>
  </div>
</template>

  <template id="_permalink-template">
  <a href="#" class="permalink">
    <span class="sr-only">Permalink</span>
    <span class="content-hash"></span>
  </a>
</template>

</div>


</body>
</html>

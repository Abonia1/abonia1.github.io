<!DOCTYPE html>
<html lang="en"><!--
 __  __                __                                     __
/\ \/\ \              /\ \             __                    /\ \
\ \ \_\ \   __  __    \_\ \      __   /\_\      __       ___ \ \ \/'\
 \ \  _  \ /\ \/\ \   /'_` \   /'__`\ \/\ \   /'__`\    /'___\\ \ , <
  \ \ \ \ \\ \ \_\ \ /\ \L\ \ /\  __/  \ \ \ /\ \L\.\_ /\ \__/ \ \ \\`\
   \ \_\ \_\\/`____ \\ \___,_\\ \____\ _\ \ \\ \__/.\_\\ \____\ \ \_\ \_\
    \/_/\/_/ `/___/> \\/__,_ / \/____//\ \_\ \\/__/\/_/ \/____/  \/_/\/_/
                /\___/                \ \____/
                \/__/                  \/___/

Powered by Hydejack v9.1.6 <https://hydejack.com/>
-->







<head>
  




  <meta name="robots" content="noindex">



  
    
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>EDA ‚Äî Visualize Embeddings of RAG | Abonia Sojasingarayar - AI &amp; ML Expert</title>
<meta name="generator" content="Jekyll v4.3.3" />
<meta property="og:title" content="EDA ‚Äî Visualize Embeddings of RAG" />
<meta name="author" content="Abonia Sojasingarayar" />
<meta property="og:locale" content="en" />
<meta name="description" content="Visualize Retrieval Augmented Generation (RAG) data using the langchain framework in conjunction with Hugging Face‚Äôs language models and embeddings and chromaDB." />
<meta property="og:description" content="Visualize Retrieval Augmented Generation (RAG) data using the langchain framework in conjunction with Hugging Face‚Äôs language models and embeddings and chromaDB." />
<link rel="canonical" href="http://localhost:4000/blogs/2024-01-05-EDA-Visualize-Embeddings-of-RAG/" />
<meta property="og:url" content="http://localhost:4000/blogs/2024-01-05-EDA-Visualize-Embeddings-of-RAG/" />
<meta property="og:site_name" content="Abonia Sojasingarayar - AI &amp; ML Expert" />
<meta property="og:image" content="http://localhost:4000/assets/img/blog/EDA-RAG.GIF" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-01-05T00:00:00+01:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="http://localhost:4000/assets/img/blog/EDA-RAG.GIF" />
<meta property="twitter:title" content="EDA ‚Äî Visualize Embeddings of RAG" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Abonia Sojasingarayar"},"dateModified":"2024-04-12T10:28:22+02:00","datePublished":"2024-01-05T00:00:00+01:00","description":"Visualize Retrieval Augmented Generation (RAG) data using the langchain framework in conjunction with Hugging Face‚Äôs language models and embeddings and chromaDB.","headline":"EDA ‚Äî Visualize Embeddings of RAG","image":"http://localhost:4000/assets/img/blog/EDA-RAG.GIF","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/blogs/2024-01-05-EDA-Visualize-Embeddings-of-RAG/"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/img/blog/logo.jpeg"},"name":"Abonia Sojasingarayar"},"url":"http://localhost:4000/blogs/2024-01-05-EDA-Visualize-Embeddings-of-RAG/"}</script>
<!-- End Jekyll SEO tag -->


  

  



  <meta name="theme-color" content="rgb(25,55,71)">


<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta http-equiv="x-ua-compatible" content="ie=edge">

<meta name="mobile-web-app-capable" content="yes">

<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-title" content="Abonia Sojasingarayar - AI & ML Expert">
<meta name="apple-mobile-web-app-status-bar-style" content="default">

<meta name="application-name" content="Abonia Sojasingarayar - AI & ML Expert">

<meta name="generator" content="Hydejack v9.1.6" />


<link rel="alternate" href="http://localhost:4000/blogs/2024-01-05-EDA-Visualize-Embeddings-of-RAG/" hreflang="en">

<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Abonia Sojasingarayar - AI &amp; ML Expert" />


<link rel="shortcut icon"    href="/assets/img/favicon.ico">
<link rel="apple-touch-icon" href="/assets/icons/icon-192x192.png">

<link rel="manifest" href="/assets/site.webmanifest">

<link rel="dns-prefetch" href="https://fonts.googleapis.com"><link rel="dns-prefetch" href="https://fonts.gstatic.com">



<link rel="preload" href="/assets/img/swipe.svg" as="image" id="_hrefSwipeSVG">






<script>!function(r,c){"use strict";function a(e,t,n,o){e.addEventListener?e.addEventListener(t,n,o):e.attachEvent?e.attachEvent("on"+t,n):e["on"+t]=n}r.loadJS=function(e,t){var n=c.createElement("script"),e=(n.src=e,t&&a(n,"load",t,{once:!0}),c.scripts[0]);return e.parentNode.insertBefore(n,e),n},r._loaded=!1,r.loadJSDeferred=function(e,t){var n=c.createElement("script");function o(){r._loaded=!0,t&&a(n,"load",t,{once:!0});var e=c.scripts[0];e.parentNode.insertBefore(n,e)}return n.src=e,r._loaded?o():a(r,"load",o,{once:!0}),n},r.setRel=r.setRelStylesheet=function(e){a(c.getElementById(e),"load",function(){this.rel="stylesheet"},{once:!0})}}(window,document);
!function(a){"use strict";var b=function(b,c,d){function e(a){return h.body?a():void setTimeout(function(){e(a)})}function f(){i.addEventListener&&i.removeEventListener("load",f),i.media=d||"all"}var g,h=a.document,i=h.createElement("link");if(c)g=c;else{var j=(h.body||h.getElementsByTagName("head")[0]).childNodes;g=j[j.length-1]}var k=h.styleSheets;i.rel="stylesheet",i.href=b,i.media="only x",e(function(){g.parentNode.insertBefore(i,c?g:g.nextSibling)});var l=function(a){for(var b=i.href,c=k.length;c--;)if(k[c].href===b)return a();setTimeout(function(){l(a)})};return i.addEventListener&&i.addEventListener("load",f),i.onloadcssdefined=l,l(f),i};"undefined"!=typeof exports?exports.loadCSS=b:a.loadCSS=b}("undefined"!=typeof global?global:this);
!function(a){if(a.loadCSS){var b=loadCSS.relpreload={};if(b.support=function(){try{return a.document.createElement("link").relList.supports("preload")}catch(b){return!1}},b.poly=function(){for(var b=a.document.getElementsByTagName("link"),c=0;c<b.length;c++){var d=b[c];"preload"===d.rel&&"style"===d.getAttribute("as")&&(a.loadCSS(d.href,d,d.getAttribute("media")),d.rel=null)}},!b.support()){b.poly();var c=a.setInterval(b.poly,300);a.addEventListener&&a.addEventListener("load",function(){b.poly(),a.clearInterval(c)}),a.attachEvent&&a.attachEvent("onload",function(){a.clearInterval(c)})}}}(this);
!function(w) {
  w._baseURL = '/';
  w._publicPath = '/assets/js/';
  w._noPushState = false;
  w._noDrawer = false;
  w._noNavbar = false;
  w._noToc = false;
  w._noSearch = false;
  w._search = {
    DATA_URL: '/assets/sitedata.json?no-cache',
    STORAGE_KEY: 'mini-search/',
    INDEX_KEY: 'index--2026-01-18T13:28:59+01:00',
  };
  w._clapButton = true;
}(window);</script>


<script async src="/assets/bower_components/MathJax/es5/tex-mml-chtml.js" id="_MathJax"></script>


<!--[if gt IE 8]><!---->

  




<link rel="stylesheet" href="/assets/css/hydejack-9.1.6.css" id="_stylePreload">
<link rel="stylesheet" href="/assets/icomoon/style.css" id="_iconsPreload">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Slab:700%7CNoto+Sans:400,400i,700,700i&display=swap" id="_fontsPreload">



  <style id="_pageStyle">

html{--accent-color: rgb(79,177,186);--accent-color-faded: rgba(79, 177, 186, 0.5);--accent-color-highlight: rgba(79, 177, 186, 0.1);--accent-color-darkened: #409ba3;--theme-color: rgb(25,55,71)}
</style>


<!--<![endif]-->


<link rel="icon" type="image/x-icon" href="/assets/img/favicon.ico">
<link rel="shortcut icon" type="image/x-icon" href="/assets/img/favicon.ico">
<link rel="apple-touch-icon" href="/assets/img/favicon.ico">

</head>

<body class="no-break-layout">
  


<hy-push-state
  id="_pushState"
  replace-selector="#_main"
  link-selector="a[href]:not([href^='/assets/']):not(.external):not(.no-push-state)"
  script-selector="script"
  duration="500"
  hashchange
>
  
  
  <div id="_navbar" class="navbar fixed-top">
  <div class="content">
    <span class="sr-only">Jump to:</span>
    <div class="nav-btn-bar">
      <a id="_menu" class="nav-btn no-hover" href="#_drawer--opened">
        <span class="sr-only">Navigation</span>
        <span class="icon-menu"></span>
      </a>
      <div class="nav-span"></div>
    </div>
  </div>
</div>
<hr class="sr-only" hidden />

  <main
  id="_main"
  class="content layout-post"
  role="main"
>
  <nav id="breadcrumbs" class="screen-only"><ul>
  
  
    <li><a href="/">home</a></li>
    
      <li>
        
          <span>/</span>
          
          
          <a href="/blogs/">blogs</a>
        
      </li>
    
      <li>
        
          <span>/</span>
          <span>2024-01-05-EDA-Visualize-Embeddings-of-RAG</span>
        
      </li>
    
  
</ul></nav>
  










<article id="post-blogs-EDA‚ÄîVisualize-Embeddings-of-RAG" class="page post mb6" role="article">
  <header>
    <h1 class="post-title flip-project-title">
      
        EDA ‚Äî Visualize Embeddings of RAG
      
    </h1>

    <div class="post-date">
      
      <span class="ellipsis mr1">
        <time datetime="2024-01-05T00:00:00+01:00">05 Jan 2024</time> in <a href="/example/" class="flip-title">Blogs</a> 
      </span>
      
        
          
          
          
            
            
            <span class="ellipsis" data-tippy-content="Last modified at: 12 Apr 2024">
              <span class="sr-only">Last modified at:</span>
              <span class="icon-history"></span>
              <time datetime="2024-04-12T10:28:22+02:00">2024-04-12</time>
            </span>
          
        
      
    </div>

    
    
      
        <div class="img-wrapper lead aspect-ratio sixteen-nine flip-project-img">
          


<img
  
    src="/assets/img/blog/EDA-RAG.GIF"
    
    
  
  alt="EDA ‚Äî Visualize Embeddings of RAG"
  
  
  width="864"
  height="486"
  loading="lazy"
/>

        </div>
      
      
    

    



  
    <p class="note-sm" >
      Visualize Retrieval Augmented Generation (RAG) data using the langchain framework in conjunction with Hugging Face‚Äôs language models and embeddings and chromaDB.

    </p>
  


  </header>

  
    <p><strong>Reading_time:</strong> 6 min<br />
  <strong>Tags:</strong> [UMAP,RAG,Visualization,Langchain,ChromaHuggingFaceEmbeddings]</p>
<ul class="large-only" id="markdown-toc">
  <li><a href="#introduction-to-rag" id="markdown-toc-introduction-to-rag">Introduction to RAG</a></li>
  <li><a href="#setting-up-the-environment" id="markdown-toc-setting-up-the-environment">Setting Up the Environment</a></li>
  <li><a href="#loading-the-model-and-vector-store" id="markdown-toc-loading-the-model-and-vector-store">Loading the Model and Vector Store</a></li>
  <li><a href="#fetching-and-preparing-data" id="markdown-toc-fetching-and-preparing-data">Fetching and Preparing Data</a></li>
  <li><a href="#calculating-distances" id="markdown-toc-calculating-distances">Calculating Distances</a></li>
  <li><a href="#visualizing-embeddings" id="markdown-toc-visualizing-embeddings">Visualizing Embeddings</a>    <ul>
      <li><a href="#1-using-spotlight" id="markdown-toc-1-using-spotlight">1. Using Spotlight</a></li>
      <li><a href="#2-using-umap" id="markdown-toc-2-using-umap">2. Using UMAP</a></li>
      <li><a href="#3-using-tensorboard" id="markdown-toc-3-using-tensorboard">3. Using Tensorboard</a></li>
      <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
    </ul>
  </li>
  <li><a href="#thanks-for-reading" id="markdown-toc-thanks-for-reading">Thanks for Reading!</a></li>
</ul>

<p>In this article, we delve into the how we can visualize Retrieval Augmented Generation (RAG) data using the langchain framework in conjunction with Hugging Face‚Äôs language models and embeddings. We‚Äôll explore how to leverage the <code class="language-plaintext highlighter-rouge">HuggingFaceEmbeddings</code> and <code class="language-plaintext highlighter-rouge">Chroma</code> vector store for efficient embedding and document retrieval, followed by a practical example of visualizing these embeddings to understand their distribution and relevance to a given question.</p>

<p>We‚Äôll explore how to use the Hugging Face Embeddings for embedding text data and store it in chroma and then visualize it using UMAP (Uniform Manifold Approximation and Projection), a dimensionality reduction technique that helps in visualizing high-dimensional data in a more interpretable way.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center"><img src="https://cdn-images-1.medium.com/max/2924/1*5nX7pJ5xOoMelSGm67hhHA.gif" alt="Courtesy of Spotlight" /></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><i>Image Credits - Courtesy of Spotlight</i></td>
    </tr>
  </tbody>
</table>

<h3 id="introduction-to-rag">Introduction to RAG</h3>

<p>RAG is a cutting-edge approach that combines the strengths of pretrained Large Language Models (LLMs) and your own data to generate responses. It retrieves documents, passes them through a sequence-to-sequence model, and then marginalizes to generate outputs. This method is particularly useful for querying specific documents or interacting with your own data in a conversational manner .</p>

<h3 id="setting-up-the-environment">Setting Up the Environment</h3>

<p>To begin, we‚Äôll need to import the necessary libraries and set up our environment. We‚Äôll use <code class="language-plaintext highlighter-rouge">pandas</code> for data manipulation, <code class="language-plaintext highlighter-rouge">langchain.embeddings</code> for handling embeddings, and <code class="language-plaintext highlighter-rouge">langchain.vectorstores</code> for our vector store.
<a href="https://python.langchain.com/docs/get_started/introduction"><strong>Introduction | ü¶úÔ∏èüîó Langchain</strong>
<em>LangChain is a framework for developing applications powered by language models. It enables applications that:</em>python.langchain.com</a></p>

<p>So do install as follow:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>!pip install pandas langchain renumics-spotlight umap-learn

import pandas as pd
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Chroma
</code></pre></div></div>

<h3 id="loading-the-model-and-vector-store">Loading the Model and Vector Store</h3>

<p>Next, we‚Äôll specify the model path for our embeddings and create instances of <code class="language-plaintext highlighter-rouge">HuggingFaceEmbeddings</code> and <code class="language-plaintext highlighter-rouge">Chroma</code>. We‚Äôll also configure the model to use the CPU/GPU for computations and ensure embeddings are not normalized for our visualization purposes.</p>

<p>Before dive in we consider, you already have chroma db collection and see how we can visualize it.If no you can create one as follow:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from langchain_community.document_loaders.recursive_url_loader import RecursiveUrlLoader
from bs4 import BeautifulSoup as Soup
from langchain.vectorstores import Chroma

url = "https://www.freenews.fr/"
loader = RecursiveUrlLoader(
    url=url, max_depth=5, extractor=lambda x: Soup(x, "lxml").text
)
documents = loader.load()
text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000, chunk_overlap=0
        )
texts = text_splitter.split_documents(documents)

modelPath = "sentence-transformers/distiluse-base-multilingual-cased-v1"

model_kwargs = {'device':'cpu'}
#encode_kwargs = {'normalize_embeddings': False}

embeddings = HuggingFaceEmbeddings(model_name=modelPath,model_kwargs=model_kwargs) 

# SAVE
docs_vectorstore = Chroma.from_documents(texts, embeddings, persist_directory="./chroma_db_multilingual")
</code></pre></div></div>

<p>Provide the link to your chroma persist_directory below:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>modelPath = "sentence-transformers/distiluse-base-multilingual-cased-v1"
model_kwargs = {'device':'cpu'}
encode_kwargs = {'normalize_embeddings': False}
embeddings_model = HuggingFaceEmbeddings(model_name=modelPath, model_kwargs=model_kwargs)
docs_vectorstore = Chroma(persist_directory="./chroma_db_multilingual", embedding_function=embeddings_model)
</code></pre></div></div>

<h3 id="fetching-and-preparing-data">Fetching and Preparing Data</h3>

<p>We‚Äôll retrieve our data from the vector store, including metadata, documents, and embeddings. Then, we‚Äôll create a DataFrame to organize this data and add a column to indicate whether each document contains the answer to our query.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>response = docs_vectorstore.get(include=["metadatas", "documents", "embeddings"])
df = pd.DataFrame({
 "id": response["ids"],
 "source": [metadata.get("source") for metadata in response["metadatas"]],
 "page": [metadata.get("page", -1) for metadata in response["metadatas"]],
 "document": response["documents"],
 "embedding": response["embeddings"],
})
df["contains_answer"] = df["document"].apply(lambda x: "N≈ìud R√©partition Optique)" in x)
</code></pre></div></div>

<h2 id="calculating-distances">Calculating Distances</h2>

<p>To find the closest match to our question, we calculate the Euclidean distance between the question embedding and each document embedding.</p>

<p><img src="https://cdn-images-1.medium.com/max/4408/1*68cE3DuXYssA7tAvtYm7-Q.png" alt="Euclidean Distance" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>question_embedding = embeddings_model.embed_query(question)
df["dist"] = df.apply(
    lambda row: np.linalg.norm(
        np.array(row["embedding"]) - question_embedding
    ),
    axis=1,
)
</code></pre></div></div>

<h2 id="visualizing-embeddings">Visualizing Embeddings</h2>

<h3 id="1-using-spotlight">1. Using Spotlight</h3>

<p>This visualization will help us understand how closely related documents are to our query and identify potential areas of improvement or further investigation.</p>

<p>Finally, we use the spotlight module from renumics to visualize the data. This step is crucial for understanding the distribution of documents in relation to the question and the model‚Äôs response.
<strong><a href="https://github.com/Renumics/spotlight">GitHub - Interactively explore unstructured datasets from your dataframe-Interactively explore unstructured datasets from your dataframe</a></strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from renumics import spotlight
spotlight.show(df)
</code></pre></div></div>

<p><img src="https://cdn-images-1.medium.com/v2/resize:fit:6776/1*jOH05LoRaN3TnJwiB9V1Dg.png" alt="UMAP ‚Äî Visualize the embeddings" /></p>

<p><strong><a href="https://github.com/Renumics/rag-demo/blob/main/notebooks/visualize_rag_tutorial.ipynb">Notebook-Renumics/rag-demo.Retrieval-Augmented Generation Assistant Demo</a></strong></p>

<h3 id="2-using-umap">2. Using UMAP</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import umap
# Find the  5 closest vectors
closest_vectors_indices = df.nsmallest(5, 'dist')['id'].values

# Prepare the embeddings for UMAP
embeddings = np.array([np.array(x) for x in df["embedding"]])

# Reduce dimensionality with UMAP
reducer = umap.UMAP()
embedding_reduced = reducer.fit_transform(embeddings)

# Plot the reduced embeddings
plt.scatter(embedding_reduced[:,  0], embedding_reduced[:,  1], c='gray', alpha=0.2)

# Highlight the question embedding and the  5 closest vectors
plt.scatter(embedding_reduced[df["id"].isin(closest_vectors_indices),  0], embedding_reduced[df["id"].isin(closest_vectors_indices),  1], c='red', alpha=1)
plt.scatter(embedding_reduced[df["id"] == df[df["dist"] == df["dist"].min()]["id"].values[0],  0], embedding_reduced[df["id"] == df[df["dist"] == df["dist"].min()]["id"].values[0],  1], c='blue', alpha=1, marker='*')

# Add labels and title
plt.title("UMAP Visualization of Text Embeddings with Question Highlighted")
plt.xlabel("UMAP  1")
plt.ylabel("UMAP  2")
plt.show()
</code></pre></div></div>

<p><img src="https://cdn-images-1.medium.com/max/2000/1*5q-fn2cWbzzJP6ielmyPxA.png" alt="UMAP ‚Äî Visualize Text embedding ‚Äî Blue point is the Question" /></p>

<h3 id="3-using-tensorboard">3. Using Tensorboard</h3>

<p>Another effective way to visualize embeddings, especially useful for gaining insights into word embeddings and the relationships between them, is by using TensorBoard. TensorBoard is a tool that allows for the visualization of machine learning models and their metrics, including word embeddings, in a user-friendly interface. It can be particularly beneficial when you want to explore the semantic similarities and relationships between words in your embeddings.</p>

<p><strong>Setting Up TensorBoard</strong></p>

<p>First, ensure you have TensorBoard installed. You can install it using pip:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip install tensorboard
</code></pre></div></div>

<p><strong>Visualizing Word Embeddings with TensorBoard</strong></p>

<p>To visualize word embeddings using TensorBoard, you‚Äôll typically need to convert your embeddings into a format that TensorBoard can understand. This often involves creating a metadata file that maps words to their embeddings and then using TensorBoard‚Äôs <code class="language-plaintext highlighter-rouge">Projector</code> to visualize these embeddings.
<strong><a href="https://www.tensorflow.org/tensorboard/get_started">Get started with TensorBoard | TensorFlow</a></strong></p>

<p>Here‚Äôs a simplified step-by-step guide on how to do this:</p>

<ol>
  <li>
    <p>Prepare Your Embeddings: Ensure your embeddings are in a suitable format. For TensorBoard, you might need to convert your embeddings into a <code class="language-plaintext highlighter-rouge">.tsv</code> (Tab-Separated Values) file where each line contains a word and its corresponding embedding vector.</p>
  </li>
  <li>
    <p>Create a Metadata File: Alongside your embeddings file, create a metadata file that maps each word to its index in the embeddings file. This file is also in <code class="language-plaintext highlighter-rouge">.tsv</code> format.</p>
  </li>
  <li>
    <p>Use TensorBoard‚Äôs Projector:
 ‚Äî Start TensorBoard by running <code class="language-plaintext highlighter-rouge">tensorboard ‚Äî logdir=path/to/your/logs</code> in your terminal.
 ‚Äî In your web browser, navigate to the TensorBoard interface (usually at <code class="language-plaintext highlighter-rouge">localhost:6006</code>).
 ‚Äî Go to the <code class="language-plaintext highlighter-rouge">Projector</code> tab.
 ‚Äî Click on <code class="language-plaintext highlighter-rouge">Load</code> under the <code class="language-plaintext highlighter-rouge">Embeddings</code> section.
 ‚Äî Upload your embeddings file and metadata file.</p>
  </li>
  <li>
    <p>Explore Your Embeddings:
 ‚Äî Once your embeddings are loaded, you can explore them in various ways, such as through a 2D or 3D scatter plot, where each point represents a word and its position is determined by its embedding vector.
 ‚Äî You can also use the <code class="language-plaintext highlighter-rouge">Word</code> search bar to find specific words and see how they are positioned relative to others in the embedding space.</p>
  </li>
</ol>

<p><img src="https://cdn-images-1.medium.com/max/5200/0*Bk4Bf3VD8P2FKl9M" alt="" /></p>

<p>-Semantic Similarity: TensorBoard makes it easier to visually inspect the semantic relationships between words by examining their positions in the embedding space.</p>
<ul>
  <li>Ease of Use: The user-friendly interface of TensorBoard allows for intuitive exploration of embeddings without the need for complex code.</li>
  <li>Insight into Model Performance: Beyond visualizing embeddings, TensorBoard can also be used to track model metrics, network weight distributions, and other performance indicators, providing a comprehensive toolkit for monitoring and understanding your models.</li>
</ul>

<h3 id="conclusion">Conclusion</h3>

<p>Visualizing RAG data provides valuable insights into the model‚Äôs decision-making process, helping us understand how it selects and interprets information from external documents.By visualizing RAG data, we gain valuable insights into the relationships between documents and our queries. This technique not only aids in understanding the performance of our RAG system but also guides us in refining models and datasets for better accuracy and relevance.</p>

<blockquote>
  <h1 id="thanks-for-reading">Thanks for Reading!</h1>
</blockquote>

  
</article>



  <hr class="dingbat related mb6" />






  
     


  <aside class="about related mt4 mb4" role="complementary">
    
    

<div class="author mt4">
  

  
    


<img
  
    src="/assets/img/blog/logo.jpeg"
    srcset="https://via.placeholder.com/128x128 1x,/assets/img/blog/logo.jpeg 2x"
    
  
  alt="Abonia Sojasingarayar"
  class="avatar"
  
  width="120"
  height="120"
  loading="lazy"
/>

  

  
  
  <h2  class="page-title hr-bottom">
    About
  </h2>

  <p>I am distinguished Machine Learning Scientist, Data Scientist, Large Language Model Engineer, NLP Engineer, and Technical Book Reviewer, holds a Masters degree in Artificial Intelligence and boasts over 7 years of experience. With a robust background in crafting and implementing ML systems across diverse domains, including cybersecurity, banking, transit,cosmetics &amp; hygiene research, and e-commerce. Find me on Medium, Google Scholar, GitHub, and LinkedIn, where I mentors others and communicates complex solutions effectively.</p>


  <div class="sidebar-social">
    <span class="sr-only">Social:</span>
<ul>
  
    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://www.linkedin.com/in/aboniasojasingarayar" title="LinkedIn" class="no-mark-external">
      <span class="icon-linkedin2"></span>
      <span class="sr-only">LinkedIn</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://github.com/Abonia1" title="GitHub" class="no-mark-external">
      <span class="icon-github"></span>
      <span class="sr-only">GitHub</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://medium.com/@abonia" title="medium" class="no-mark-external">
      <span class="icon-link"></span>
      <span class="sr-only">medium</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://www.youtube.com/channel/UCGphGM_oeR4r9dqVs71Jc5w" title="YouTube" class="no-mark-external">
      <span class="icon-youtube"></span>
      <span class="sr-only">YouTube</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://twitter.com/AboniaJesse" title="Twitter" class="no-mark-external">
      <span class="icon-twitter"></span>
      <span class="sr-only">Twitter</span>
    </a>
  </li>


    
  
</ul>

  </div>
</div>

  </aside>


  

  
  

  
    


  <aside class="related mb4" role="complementary">  <h2 class="hr-bottom">Related Posts</h2>  <ul class="related-posts">                  <li class="h4">  <a href="/blogs/2026-01-18-E-book-release-From-Research-to-Production-Industrializing-NLP-and-Large-Language-Model/" class="flip-title"><span>E-Book - From Research to Production - Industrializing NLP and Large Language Models</span></a>  <time class="faded fine" datetime="2026-01-18T00:00:00+01:00">18 Jan 2026</time></li>                        <li class="h4">  <a href="/blogs/2025-05-01-Deploying-Scalable-Machine-Learning-Service-on-Kubernetes/" class="flip-title"><span>Deploying a Scalable Machine Learning Service on Kubernetes</span></a>  <time class="faded fine" datetime="2025-05-01T00:00:00+02:00">01 May 2025</time></li>                        <li class="h4">  <a href="/blogs/2025-03-02-Kafka-Building-Scalable-data-Processing-Pipeline-with-Kafka-and-docker-compose/" class="flip-title"><span>Building a Scalable data Processing Pipeline with Kafka and Docker Compose</span></a>  <time class="faded fine" datetime="2025-03-02T00:00:00+01:00">02 Mar 2025</time></li>            </ul></aside>

  

  
  

  
    

  


  
<footer class="content" role="contentinfo">
  <hr/>
  
    <p><small class="copyright">¬© 2024. All rights reserved.
</small></p>
  
  
    <nav class="legal"><small>
    
      
      <a class="heading flip-title" href="/LICENSE/">LICENSE</a>
      
    
    </small></nav>
  
    <p><small>Powered by <a class="external" href="https://hydejack.com/">Hydejack</a> v<span id="_version">9.1.6</span></small></p>
  <hr class="sr-only"/>
</footer>


</main>

  <hy-drawer
  id="_drawer"
  class=""
  side="left"
  threshold="10"
  noscroll
  
>
  <header id="_sidebar" class="sidebar" role="banner">
    




<div class="sidebar-bg sidebar-overlay" style="background-color:rgb(25,55,71);background-image:url(/assets/img/sidebar-bg.jpg)"></div>

    <div class="sidebar-sticky">
  <div class="sidebar-about">
    
      <a class="no-hover" href="/" tabindex="-1">
        <img src="/assets/img/blog/logo.jpeg" class="avatar" alt="Abonia Sojasingarayar - AI & ML Expert" width="120" height="120" loading="lazy" />
      </a>
    
    <a class="sidebar-title" href="/"><h2 class="h1">Abonia Sojasingarayar - AI & ML Expert</h2></a>
    
    
      <p class="">
        <table>
  <tbody>
    <tr>
      <td>4x Linkedin Top Voice</td>
      <td>Machine Learning, DS &amp; MLOps</td>
      <td>Author</td>
    </tr>
  </tbody>
</table>

      </p>
    
  </div>

  <nav class="sidebar-nav heading" role="navigation">
    <span class="sr-only">Navigation:</span>
<ul>
  
    
      
      <li>
        <a
          id="_drawer--opened"
          href="/example/"
          class="sidebar-nav-item "
          
        >
          Blogs
        </a>
      </li>
    
      
      <li>
        <a
          
          href="/about/"
          class="sidebar-nav-item "
          
        >
          About
        </a>
      </li>
    
      
      <li>
        <a
          
          href="/newsletter/"
          class="sidebar-nav-item "
          
        >
          Newsletter
        </a>
      </li>
    
      
      <li>
        <a
          
          href="https://aboniasojasingarayar.substack.com/"
          class="sidebar-nav-item "
          
        >
          AI Magazine
        </a>
      </li>
    
  
</ul>

  </nav>

  
  <div class="sidebar-social">
    <span class="sr-only">Social:</span>
<ul>
  
    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://www.linkedin.com/in/aboniasojasingarayar" title="LinkedIn" class="no-mark-external">
      <span class="icon-linkedin2"></span>
      <span class="sr-only">LinkedIn</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://github.com/Abonia1" title="GitHub" class="no-mark-external">
      <span class="icon-github"></span>
      <span class="sr-only">GitHub</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://medium.com/@abonia" title="medium" class="no-mark-external">
      <span class="icon-link"></span>
      <span class="sr-only">medium</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://www.youtube.com/channel/UCGphGM_oeR4r9dqVs71Jc5w" title="YouTube" class="no-mark-external">
      <span class="icon-youtube"></span>
      <span class="sr-only">YouTube</span>
    </a>
  </li>


    
      



  

  
  
  
  

  

  

  <li>
    <a href="https://twitter.com/AboniaJesse" title="Twitter" class="no-mark-external">
      <span class="icon-twitter"></span>
      <span class="sr-only">Twitter</span>
    </a>
  </li>


    
  
</ul>

  </div>
</div>
  </header>
</hy-drawer>
<hr class="sr-only" hidden />

</hy-push-state>


  <!--[if gt IE 10]><!---->
  <script nomodule>!function(){var t,n=document.createElement("script");!("noModule"in n)&&"onbeforeload"in n&&(t=!1,document.addEventListener("beforeload",function(e){if(e.target===n)t=!0;else if(!e.target.hasAttribute("nomodule")||!t)return;e.preventDefault()},!0),n.type="module",n.src=".",document.head.appendChild(n),n.remove())}();
</script>
  <script src="/assets/js/hydejack-9.1.6.js" type="module"></script>
  <script src="/assets/js/LEGACY-hydejack-9.1.6.js" nomodule defer></script>
  

  

<!--<![endif]-->
  <!-- <script>
  document.querySelector('hy-push-state').setAttribute('prefetch', '');

  document.querySelectorAll('.sidebar a[href^="/"]').forEach(function (el) { 
    el.addEventListener('click', function (e) {
      if (el.pathname === window.location.pathname) {
        e.preventDefault();
        e.stopPropagation();
        document.querySelector('hy-drawer').close();
      }
    });
  });
</script> -->

<!--
Code for integrating CloudFlare's email protection with Hydejack's single page app loading.
-->
<script>
  document.getElementById('_pushState').addEventListener('hy-push-state-after', function (e) {
    function e(e){
      (console.error?console.error:console.log).call(console,e)
    }

    function t(e){
      return l.innerHTML='<a href="'+e.replace(/"/g,"&quot;")+'"></a>',l.childNodes[0].getAttribute("href")
    }

    function r(e,t){
      var r=e.substr(t,2);return parseInt(r,16)
    }

    function n(e,n){
      for(var o="",c=r(e,n),a=n+2;a<e.length;a+=2){
        var l=r(e,a)^c;
        o+=String.fromCharCode(l)
      }
      return t(o)
    }

    var o="/cdn-cgi/l/email-protection#",
        c=".__cf_email__",
        a="data-cfemail",
        l=document.createElement("div");

    !function(){
      for(var t=document.getElementsByTagName("a"),r=0;r<t.length;r++)
        try{
          var c=t[r],a=c.href.indexOf(o);
          a>-1&&(c.href="mailto:"+n(c.href,a+o.length))
        }catch(t){
          e(t)
        }
    }(),
    function(){
      for(var t=document.querySelectorAll(c),r=0;r<t.length;r++)
        try{
          var o=t[r],l=n(o.getAttribute(a),0),i=document.createTextNode(l);
          o.parentNode.replaceChild(i,o)
        }catch(t){
          e(t)
        }
    }()
  });
</script>





<div hidden>
  
  <h2 class="sr-only">Templates (for web app):</h2>

  <template id="_animation-template">
  <div class="animation-main fixed-top">
    <nav id="breadcrumbs" class="screen-only"><ul>
  
  
</ul></nav>
    <div class="content">
      <div class="page"></div>
    </div>
  </div>
</template>

  <template id="_loading-template">
  <div class="loading nav-btn fr">
    <span class="sr-only">Loading‚Ä¶</span>
    <span class="icon-cog"></span>
  </div>
</template>

  <template id="_error-template">
  <div class="page">
    <h1 class="page-title">Error</h1>
    
    
    <p class="lead">
      Sorry, an error occurred while loading <a class="this-link" href=""></a>.

    </p>
  </div>
</template>

  <template id="_permalink-template">
  <a href="#" class="permalink">
    <span class="sr-only">Permalink</span>
    <span class="content-hash"></span>
  </a>
</template>

</div>


</body>
</html>
